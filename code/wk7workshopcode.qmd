---
title: "Week7workshopcode"
format: html
execute:
  warning: false
  message: false
---

#set up

```{r installing new packages}
#install.packages("performance")
#install.packages("broom")
#install.packages("flextable")
#install.packages("ggeffects")
#install.packages("car")
```


```{r libraries}
# should haves
library(tidyverse)
library(here)
library(lterdatasampler)

# would be nice to have
library(performance)
library(broom)
library(flextable)
library(ggeffects)
library(car)
```

```{r}
view(hbr_maples)
```


```{r}
#linear models
 #how does stem length predict stem dry mass
maples_data<-hbr_maples%>%
  filter(year== 2003 & watershed == "Reference")
view(maples_data)
```
```{r}
#making the model
ggplot(data = maples_data, aes(x = stem_length, y = stem_dry_mass)) +
  geom_point()
```
```{r}
#checking the assumptions
modelobject <- lm(stem_dry_mass ~ stem_length, data = maples_data)

# par sets plot parameters and mfrow makes the viewer pane show a 2x2 grid of plots
# format: par(mfrow = c(number of rows, number of columns))
par(mfrow = c(2, 2))
# turns off the 2x2 grid - pop this under the code chunk where you set the 2x2 grid
dev.off()
plot(modelobject)

```

Checking assumptions for linear model

1. linear relationship between variables: yes (exploratory data showed this)
2. independence of errors- yes (how data was collected)
3. homoskedasticity- yes (residuals v fitted plot/scale-location plots)
4. normally distributed errrors- yes (qqplot)


```{r mkaing model predictions}
# extract model predictions using ggpredict
predictions <- ggpredict(modelobject, terms = "stem_length")

predictions
```

```{r}
#making a plot of the predictions
plot_predictions <- ggplot(data = maples_data, 
                           aes(x = stem_length, y = stem_dry_mass)) +
  # first plot the underlying data from maples_data
  geom_point() +
  # then plot the predictions
  geom_line(data = predictions, 
            aes(x = x, y = predicted), 
            color = "blue", linewidth = 1) +
  # then plot the 95% confidence interval from ggpredict
  geom_ribbon(data = predictions, 
              aes(x = x, y = predicted, ymin = conf.low, ymax = conf.high), 
              alpha = 0.2) +
  # theme and meaningful labels
  theme_bw() +
  labs(x = "Stem length (mm)",
       y = "Stem dry mass (g)")

plot_predictions
```

```{r}
# store the model summary as an object
model_summary <- summary(modelobject)

# store the ANOVA table as an object
# anova(): special function to get analysis of variance tables for a model
model_squares <- anova(modelobject)

model_summary
```

```{r}
#making a table of the summary
model_squares_table <- tidy(model_squares) %>% 
  # round the sum of squares and mean squares columns to have 5 digits (could be less)
  mutate(across(sumsq:meansq, ~ round(.x, digits = 5))) %>% 
  # round the F-statistic to have 1 digit
  mutate(statistic = round(statistic, digits = 1)) %>% 
  # replace the very very very small p value with < 0.001
  mutate(p.value = case_when(
    p.value < 0.001 ~ "< 0.001"
  )) %>% 
  # rename the stem_length cell to be meaningful
  mutate(term = case_when(
    term == "stem_length" ~ "Stem length (mm)",
    TRUE ~ term
  )) %>% 
  # make the data frame a flextable object
  flextable() %>% 
  # change the header labels to be meaningful
  set_header_labels(df = "Degrees of Freedom", 
                    sumsq = "Sum of squares",
                    meansq = "Mean squares",
                    statistic = "F-statistic",
                    p.value = "p-value")

model_squares_table
```


















































































